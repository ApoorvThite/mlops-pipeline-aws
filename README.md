# ğŸ” Automated MLOps Pipeline on AWS

An end-to-end MLOps pipeline that trains, deploys, and monitors a machine learning model using AWS SageMaker. This project demonstrates best practices in CI/CD for ML systems, leveraging the power of automation for robust model management in production environments.

---

## ğŸš€ Project Overview

This project sets up a fully automated MLOps pipeline using:

- **AWS SageMaker** for model training and hosting  
- **GitHub Actions** for CI/CD  
- **S3** for data and artifact storage  
- **SageMaker Model Monitor** for automated model quality tracking  
- **IAM & OIDC** for secure role-based access control

---

## ğŸ§  Problem Statement

We build a binary classification model using Scikit-learn to solve a supervised ML task, and:

1. Train the model via **SageMaker training jobs**
2. Automatically deploy the model to an endpoint
3. Continuously monitor the modelâ€™s prediction drift and performance degradation using **Model Monitor**

---

## ğŸ› ï¸ Tech Stack

| Layer           | Tools                                         |
|----------------|-----------------------------------------------|
| Model Training | `scikit-learn`, `SageMaker Python SDK`        |
| Deployment     | `SageMaker Hosting`, `Boto3`, `S3`            |
| Monitoring     | `SageMaker Model Monitor`                     |
| CI/CD          | `GitHub Actions`, `OIDC`, `IAM Roles`         |
| Infrastructure | `AWS S3`, `IAM`, `SageMaker`, `CloudWatch`    |

---

## ğŸ“ Project Structure

```
mlops-pipeline-aws/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ titanic.csv # Sample dataset
â”œâ”€â”€ train.py # Local training script
â”œâ”€â”€ sagemaker_train_deploy.py # Launch training job on SageMaker
â”œâ”€â”€ sagemaker_deploy_endpoint.py # Deploy trained model to SageMaker endpoint
â”œâ”€â”€ sagemaker_monitor.py (WIP) # Model monitoring script
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project overview and instructions

```

---

## ğŸ”§ How to Run

### 1. ğŸ”‘ Prerequisites

- AWS Account with SageMaker, S3, and IAM permissions
- S3 bucket created (e.g., `apoorvawsbucket321`)
- AWS CLI configured locally (`aws configure`)
- Python 3.8+ with `boto3`, `sagemaker`, `joblib`

### 2. ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

3. ğŸš‚ Start Training

```bash
python sagemaker_train_deploy.py
```

4. ğŸŒ Deploy Endpoint

Edit sagemaker_deploy_endpoint.py and set:

```bash
python sagemaker_deploy_endpoint.py
```

---

## âœ… Results

The trained model achieved:

- **Accuracy:** ~76%
- **F1-Score:** 0.75 (macro average)
- **Model File:** `model.joblib` (saved locally and uploaded to S3)
- **Deployed Endpoint:** Successfully created on AWS SageMaker and ready for inference via REST API

---

## ğŸ“ˆ What's Next

- âœ… **Integrate Model Monitor** for real-time drift detection  
- âœ… **Set up GitHub Actions** for full CI/CD automation  
- â³ **Add real-time prediction script** to send requests to the endpoint  
- â³ **Create a Streamlit UI** for easy user interaction  


Let me know if you'd like me to add:
- Diagrams (architecture/CI flow)
- Badges (e.g. deployment status)
- GitHub Actions workflow YAML
- Live demo links

I'm happy to help polish the final version!
